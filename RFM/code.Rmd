---
title: "RFM"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
library(dplyr)
library(ggplot2)
library(tidyverse)
#library(stringr)
#library(DT)
library(tidyr)
library(knitr)
library(rmarkdown)
library(plotly)
library("NbClust")
library("cluster")
library("clustertend")
library("factoextra")
library("magrittr")
library(shiny)
library(fpc)
library(dbscan)
library("NbClust")
library(clValid)
```

```{r}
##Load Dataset
df_data <- fread('../data.csv') 

glimpse(df_data)

```

#Data cleaning
1. handle outliers
2. handle missing values

```{r}
### Data Cleaning
#Delete all negative Quantity and Price. We also need to delete NA customer ID
df_data <- df_data %>% 
  mutate(Quantity = replace(Quantity, Quantity<=0, NA),
         UnitPrice = replace(UnitPrice, UnitPrice<=0, NA))

df_data <- df_data %>%
  drop_na()
```

```{r}
###delete outliers!!!
```


```{r}
### Recode variables
#We should do some recoding and convert character variables to factors.

df_data <- df_data %>% 
  mutate(InvoiceNo=as.factor(InvoiceNo), StockCode=as.factor(StockCode), 
         InvoiceDate=as.Date(InvoiceDate, '%m/%d/%Y %H:%M'), CustomerID=as.factor(CustomerID), 
         Country=as.factor(Country))

df_data <- df_data %>% 
  mutate(total_dolar = Quantity*UnitPrice)

glimpse(df_data)
```


### Calculate RFM {.tabset}
To implement the RFM analysis, we need to further process the data set in by the following steps:

1. Find the most recent date for each ID and calculate the days to the now or some other date, to get the Recency data
2. Calculate the quantity of translations of a customer, to get the Frequency data
3. Sum the amount of money a customer spent and divide it by Frequency, to get the amount per transaction on average, that is the Monetary data.

```{r results='hold'}

df_RFM <- df_data %>% 
  group_by(CustomerID) %>% 
  summarise(recency=as.numeric(as.Date("2012-01-01")-max(InvoiceDate)),
            frequenci=n_distinct(InvoiceNo), monitery= sum(total_dolar)/n_distinct(InvoiceNo)) 

#summary(df_RFM)

#kable(head(df_RFM))
```


#### Recency
#Recency – How recently did the customer purchase?
```{r} 
hist(df_RFM$recency)
```


#### Frequency
#Frequency – How often do they purchase?
```{r} 
hist(df_RFM$frequenci, breaks = 50)
```


#### Monetary
#Monetary Value – How much do they spend?
```{r} 
hist(df_RFM$monitery, breaks = 50)
```

#Because the data is realy skewed, we use log scale to normalize
```{r}
df_RFM$monitery <- log(df_RFM$monitery)
#hist(df_RFM$log_monitery)
```


#Plots
```{r}
#Plotting the data R Vs F
ggplot(data = df_RFM, mapping = aes(x=df_RFM$recency, y=df_RFM$monitery)) +
       geom_point(size=3)
```



```{r}
#New approach for segmentation

df_RFM$Recency_group <- cut(df_RFM$recency, 
                              quantile(df_RFM$recency, 
                              probs=seq(0,1,0.25)), 
                              ordered_result=T, 
                              include.lowest=T) # segment data into groups

df_RFM$Recency_group <- factor(df_RFM$Recency_group, 
                                 labels=c("very recent", "recent", "old", "oldest")) # rename levels


df_RFM$Frequency_group <- cut(df_RFM$frequenci, 
                              c(0,1,3,10,188), 
                              ordered_result=T) #segment into four groups

df_RFM$Frequency_group <- factor(df_RFM$Frequency_group, 
                                 labels=c("very rare", "rare", "frequent", "very frequent"))


df_RFM$mon_value_group <- cut(df_RFM$monitery, 
                              quantile(df_RFM$monitery, probs=seq(0,1,0.25)), 
                              ordered_result=T, include.lowest=T) #segment into groups

df_RFM$mon_value_group <- factor(df_RFM$mon_value_group, 
                                 labels=c("small", "medium", "large", "very large")) #rename levels
```

```{r}
#Visualize the results

ggplot(df_RFM, aes(Recency_group, Frequency_group)) +
  geom_count() +
  facet_grid(mon_value_group ~ .) +
  labs(x="Recency", y="Frequency", title="RFM analysis") 
```


#-----------------------------------------------
# Clustering
#-----------------------------------------------

##We first have to scale the R,F,M values
```{r}
#scale dataframe
df_RFM2 <- df_RFM[1:4]
row.names(df_RFM2) <- df_RFM2$CustomerID
df_RFM2$CustomerID <- NULL

df_RFM2 <- scale(df_RFM2,scale = TRUE)
summary(df_RFM2)
```

##Assessing cluster tendency
```{r}
#Data preparation
##################
fviz_pca_ind(prcomp(df_RFM2), title = "PCA(principal compontent analysis) - RFM2",                    # Plot faithful data set
             palette = "jco", geom = "point", ggtheme = theme_classic(), legend = "bottom")

```

```{r}
#Hopkins statistics
#A value for H higher than 0.75 indicates a clustering tendency at the 90% confidence level.
#The null and the alternative hypotheses are defined as follow: 
#1.) Null hypothesis: the data set D is uniformly distributed (i.e., no meaningful clusters) 
#2.) Alternative hypothesis: the data set D is not uniformly distributed (i.e., contains meaningful clusters)

# Compute Hopkins statistic for df_RFM2 dataset
hop.res <- get_clust_tendency(df_RFM2, n = nrow(df_RFM2)-1, graph = FALSE)
hop.res$hopkins_stat


```
##Optimal number of clusters

```{r}
#Average silhouette method
#Average silhouette method computes the average silhouette of observations for different values of k. The optimal number of clusters k is the #one that maximize the average silhouette over a range of possible values for k (Kaufman and Rousseeuw 1990).
silhoutte.res <- fviz_nbclust(df_RFM2, kmeans, method = "silhouette")+ labs(subtitle = "Silhouette method")


#Gap statistic
#The gap statistic has been published by R. Tibshirani et al. The approach can be applied to any clustering method.The gap statistic compares the total within intra-cluster variation for different values of k with their expected values under null reference distribution of the data. The estimate of the optimal clusters will be value that maximize the gap statistic.

set.seed(123)
gapstat.res <- fviz_nbclust(df_RFM2, kmeans, nstart = 25,  method = "gap_stat", nboot = 500)+ labs(subtitle = "Gap statistic method")

#NbClust() function: 30 indices for choosing the best number of clusters

nbclust.res <- NbClust(data = df_RFM2, diss = NULL, distance = "euclidean", min.nc = 2, max.nc = 15, method = kmeans)

```

##clustering methods:
```{r}
##get dist measurement
res.dist <- get_dist(df_RFM2, stand = TRUE, method = "pearson")

```

```{r}
#partitioning clustering: k menoid, k means and clara
set.seed(123)

fviz_nbclust(df_RFM2, kmeans, method = "gap_stat")#Determining the optimal number of clusters: 

kmeans.res <- kmeans(df_RFM2, 3, nstart = 25)#kmeans with k = 3
head(kmeans.res$cluster)#to see the clusters

fviz_cluster(kmeans.res, data = df_RFM2,
             ellipse.type = "convex",
             palette = "jco",
             ggtheme = theme_minimal())#visualize kmeans

pam.res <- pam(df_RFM2, 3) #kmeanoid clustering method - less sensitve to outliers
fviz_cluster(pam.res)

#CLARA: better for large datasets; using sampling approach
clara.res <- clara(df_RFM2, 3, metric = "euclidean", stand = FALSE, samples = 50, pamLike = FALSE)
clara.res$clustering



ddf_RFM <- cbind(df_RFM2, cluster = clara.res$cluster)#to implement the clusters

```

```{r}
#hierarchiacal clustering , ward
hc.res <- eclust(df_RFM2, "hclust", k = 3, hc_metric = "euclidean", hc_method = "ward.D2", graph = FALSE)

# Visualize dendrograms
fviz_dend(hc.res, show_labels = FALSE,
         palette = "jco", as.ggplot = TRUE)
```

```{r}
#fuzzy clustering method: c means

#fanny(x, k, metric = "euclidean", stand = FALSE)#template version
fanny.res <- fanny(df_RFM2, 3, metric = "euclidean", stand = TRUE)
```

```{r}
#DBSCAN method
set.seed(123)
dbscan.res <- fpc::dbscan(df_RFM2, eps = 0.15, MinPts = 5)
head(dbscan.res$cluster)
print.dbscan(dbscan.res)#zero is outlier

fviz_cluster(dbscan.res, data = df_RFM2, stand = FALSE, #to visualize, with black is outlier
             ellipse = FALSE, show.clust.cent = FALSE,
             geom = "point",palette = "jco", ggtheme = theme_classic())


dbscan::kNNdistplot(df_RFM2, k =  5)#evaluate together with abline command
abline(h = 0.15, lty = 2)#to find best epsilon


```

#Cluster analysis
```{r}
#Silhouette plot
#A value of S close to 1 indicates that the object is well clustered. In the other words, the object i is similar to the other objects in its group.
fviz_silhouette(hc.res)


#It can be seen that several samples, in cluster 2, have a negative silhouette coefficient. This means that they are not in the right cluster. We can find the name of these samples and determine the clusters they are closer (neighbor cluster), as follow:

sil <- hc.res$silinfo$widths[, 1:3]# Silhouette width of observation

neg_sil_index <- which(sil[, 'sil_width'] < 0)
sil[neg_sil_index, , drop = FALSE]# Objects with negative silhouette



#Dun Index

clust_stats <- cluster.stats(dist(df_RFM2),  kmeans.res$cluster)# Statistics for k-means clustering
clust_stats$dun# Dun index

clust_stats$corrected.rand# Corrected Rand index
```

#Comparing clustering algorithms
```{r}
library(clValid)
# Compute clValid
clmethods <- c("hierarchical","kmeans","pam","fanny","clara")
intern <- clValid(df_RFM2, nClust = 2:6, clMethods = clmethods, validation = "internal")
# Summary
summary(intern)

# Stability measures
stab <- clValid(df, nClust = 2:6, clMethods = clmethods, validation = "stability")
# Display only optimal Scores
optimalScores(stab)
```

#------------------------------------------------




```{r}
#### Cut
members <- cutree(c,k = 8)

members[1:5]
table(members)

aggregate(df_RFM[,2:4], by=list(members), mean)

```





```{r}
library("Rtsne")
gower_dist <- daisy(df_RFM2, metric = "gower", type = list(logratio = 3))
pam_fit <- pam(gower_dist, diss = TRUE, k = 7)
Customer_Data <- cbind(df_RFM2, Group = pam_fit$clustering)
tsne_obj <- Rtsne(gower_dist, is_distance = TRUE)
tsne_data <- tsne_obj$Y %>%
  data.frame() %>%
  setNames(c("X", "Y")) %>%
  mutate(cluster = factor(pam_fit$clustering))

ggplot(aes(x = X, y = Y), data = tsne_data) + geom_point(aes(color = cluster)) + ggtitle("PAM") + theme(plot.title = element_text(hjust = 0.5))
```






#prediction?

#visualization

```{r}

p <- plot_ly(z = df_RFM, type = "heatmap")
p

```

```{r}
library("htmlwidgets")
p=ggplot(df_RFM, aes(x=df_RFM$frequenci, y=df_RFM$log_monitery, color=Recency_group)) + 
    geom_point(size=6, alpha=0.6)
ggplotly(p)
p %>% offline(height = 600)

saveWidget(p,file = "inter.html")
```


```{r}
mytext=paste("Frequency = ", df_RFM$frequenci, "\n" , "Monetary = ", df_RFM$monitery, "\n", "Row Number: ",rownames(df_RFM),  sep="")    
pp=plotly_build(p)   
style( pp, text=mytext, hoverinfo = "text", traces = c(1, 2, 3) )
pp %>% offline(height = 600)
htmlwidgets::saveWidget(as_widget(p), "index.html")

```


```{r}

# left
p1 <- plot_ly(df_RFM, x = ~df_RFM$frequenci, y = ~df_RFM$monitery , type="scatter", mode = "markers", 
        marker=list( size=20 , opacity=0.5), color = ~df_RFM$recency)
p1 %>% offline(height = 600)
```




```{r}
library(factoextra)
df_RFM$log_recency <- log(df_RFM$recency)
df_RFM$log_frequency <- log(df_RFM$frequenci)
df_RFM$log_monitery <- log(df_RFM$monitery)

write.csv(df_RFM, file = "rfm.csv")
```

```{r}
save(df_RFM, file = "data.RData")
```



